{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: ctransformers==0.2.5 in /Users/rachana/experiments/End-to-end-Medical-Chatbot-using-Llama2/.conda/lib/python3.8/site-packages (0.2.5)\n",
      "Requirement already satisfied: huggingface-hub in /Users/rachana/experiments/End-to-end-Medical-Chatbot-using-Llama2/.conda/lib/python3.8/site-packages (from ctransformers==0.2.5) (0.22.2)\n",
      "Requirement already satisfied: filelock in /Users/rachana/experiments/End-to-end-Medical-Chatbot-using-Llama2/.conda/lib/python3.8/site-packages (from huggingface-hub->ctransformers==0.2.5) (3.13.3)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /Users/rachana/experiments/End-to-end-Medical-Chatbot-using-Llama2/.conda/lib/python3.8/site-packages (from huggingface-hub->ctransformers==0.2.5) (2023.12.2)\n",
      "Requirement already satisfied: packaging>=20.9 in /Users/rachana/experiments/End-to-end-Medical-Chatbot-using-Llama2/.conda/lib/python3.8/site-packages (from huggingface-hub->ctransformers==0.2.5) (23.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /Users/rachana/experiments/End-to-end-Medical-Chatbot-using-Llama2/.conda/lib/python3.8/site-packages (from huggingface-hub->ctransformers==0.2.5) (6.0.1)\n",
      "Requirement already satisfied: requests in /Users/rachana/experiments/End-to-end-Medical-Chatbot-using-Llama2/.conda/lib/python3.8/site-packages (from huggingface-hub->ctransformers==0.2.5) (2.31.0)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in /Users/rachana/experiments/End-to-end-Medical-Chatbot-using-Llama2/.conda/lib/python3.8/site-packages (from huggingface-hub->ctransformers==0.2.5) (4.66.2)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /Users/rachana/experiments/End-to-end-Medical-Chatbot-using-Llama2/.conda/lib/python3.8/site-packages (from huggingface-hub->ctransformers==0.2.5) (4.11.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/rachana/experiments/End-to-end-Medical-Chatbot-using-Llama2/.conda/lib/python3.8/site-packages (from requests->huggingface-hub->ctransformers==0.2.5) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/rachana/experiments/End-to-end-Medical-Chatbot-using-Llama2/.conda/lib/python3.8/site-packages (from requests->huggingface-hub->ctransformers==0.2.5) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/rachana/experiments/End-to-end-Medical-Chatbot-using-Llama2/.conda/lib/python3.8/site-packages (from requests->huggingface-hub->ctransformers==0.2.5) (1.26.18)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/rachana/experiments/End-to-end-Medical-Chatbot-using-Llama2/.conda/lib/python3.8/site-packages (from requests->huggingface-hub->ctransformers==0.2.5) (2024.2.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: sentence-transformers==2.2.2 in /Users/rachana/experiments/End-to-end-Medical-Chatbot-using-Llama2/.conda/lib/python3.8/site-packages (2.2.2)\n",
      "Requirement already satisfied: transformers<5.0.0,>=4.6.0 in /Users/rachana/experiments/End-to-end-Medical-Chatbot-using-Llama2/.conda/lib/python3.8/site-packages (from sentence-transformers==2.2.2) (4.39.3)\n",
      "Requirement already satisfied: tqdm in /Users/rachana/experiments/End-to-end-Medical-Chatbot-using-Llama2/.conda/lib/python3.8/site-packages (from sentence-transformers==2.2.2) (4.66.2)\n",
      "Requirement already satisfied: torch>=1.6.0 in /Users/rachana/experiments/End-to-end-Medical-Chatbot-using-Llama2/.conda/lib/python3.8/site-packages (from sentence-transformers==2.2.2) (2.2.2)\n",
      "Requirement already satisfied: torchvision in /Users/rachana/experiments/End-to-end-Medical-Chatbot-using-Llama2/.conda/lib/python3.8/site-packages (from sentence-transformers==2.2.2) (0.17.2)\n",
      "Requirement already satisfied: numpy in /Users/rachana/experiments/End-to-end-Medical-Chatbot-using-Llama2/.conda/lib/python3.8/site-packages (from sentence-transformers==2.2.2) (1.24.4)\n",
      "Requirement already satisfied: scikit-learn in /Users/rachana/experiments/End-to-end-Medical-Chatbot-using-Llama2/.conda/lib/python3.8/site-packages (from sentence-transformers==2.2.2) (1.3.2)\n",
      "Requirement already satisfied: scipy in /Users/rachana/experiments/End-to-end-Medical-Chatbot-using-Llama2/.conda/lib/python3.8/site-packages (from sentence-transformers==2.2.2) (1.10.1)\n",
      "Requirement already satisfied: nltk in /Users/rachana/experiments/End-to-end-Medical-Chatbot-using-Llama2/.conda/lib/python3.8/site-packages (from sentence-transformers==2.2.2) (3.8.1)\n",
      "Requirement already satisfied: sentencepiece in /Users/rachana/experiments/End-to-end-Medical-Chatbot-using-Llama2/.conda/lib/python3.8/site-packages (from sentence-transformers==2.2.2) (0.2.0)\n",
      "Requirement already satisfied: huggingface-hub>=0.4.0 in /Users/rachana/experiments/End-to-end-Medical-Chatbot-using-Llama2/.conda/lib/python3.8/site-packages (from sentence-transformers==2.2.2) (0.22.2)\n",
      "Requirement already satisfied: filelock in /Users/rachana/experiments/End-to-end-Medical-Chatbot-using-Llama2/.conda/lib/python3.8/site-packages (from huggingface-hub>=0.4.0->sentence-transformers==2.2.2) (3.13.3)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /Users/rachana/experiments/End-to-end-Medical-Chatbot-using-Llama2/.conda/lib/python3.8/site-packages (from huggingface-hub>=0.4.0->sentence-transformers==2.2.2) (2023.12.2)\n",
      "Requirement already satisfied: packaging>=20.9 in /Users/rachana/experiments/End-to-end-Medical-Chatbot-using-Llama2/.conda/lib/python3.8/site-packages (from huggingface-hub>=0.4.0->sentence-transformers==2.2.2) (23.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /Users/rachana/experiments/End-to-end-Medical-Chatbot-using-Llama2/.conda/lib/python3.8/site-packages (from huggingface-hub>=0.4.0->sentence-transformers==2.2.2) (6.0.1)\n",
      "Requirement already satisfied: requests in /Users/rachana/experiments/End-to-end-Medical-Chatbot-using-Llama2/.conda/lib/python3.8/site-packages (from huggingface-hub>=0.4.0->sentence-transformers==2.2.2) (2.31.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /Users/rachana/experiments/End-to-end-Medical-Chatbot-using-Llama2/.conda/lib/python3.8/site-packages (from huggingface-hub>=0.4.0->sentence-transformers==2.2.2) (4.11.0)\n",
      "Requirement already satisfied: sympy in /Users/rachana/experiments/End-to-end-Medical-Chatbot-using-Llama2/.conda/lib/python3.8/site-packages (from torch>=1.6.0->sentence-transformers==2.2.2) (1.12)\n",
      "Requirement already satisfied: networkx in /Users/rachana/experiments/End-to-end-Medical-Chatbot-using-Llama2/.conda/lib/python3.8/site-packages (from torch>=1.6.0->sentence-transformers==2.2.2) (3.1)\n",
      "Requirement already satisfied: jinja2 in /Users/rachana/experiments/End-to-end-Medical-Chatbot-using-Llama2/.conda/lib/python3.8/site-packages (from torch>=1.6.0->sentence-transformers==2.2.2) (3.1.3)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /Users/rachana/experiments/End-to-end-Medical-Chatbot-using-Llama2/.conda/lib/python3.8/site-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers==2.2.2) (2023.12.25)\n",
      "Requirement already satisfied: tokenizers<0.19,>=0.14 in /Users/rachana/experiments/End-to-end-Medical-Chatbot-using-Llama2/.conda/lib/python3.8/site-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers==2.2.2) (0.15.2)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /Users/rachana/experiments/End-to-end-Medical-Chatbot-using-Llama2/.conda/lib/python3.8/site-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers==2.2.2) (0.4.2)\n",
      "Requirement already satisfied: click in /Users/rachana/experiments/End-to-end-Medical-Chatbot-using-Llama2/.conda/lib/python3.8/site-packages (from nltk->sentence-transformers==2.2.2) (8.1.7)\n",
      "Requirement already satisfied: joblib in /Users/rachana/experiments/End-to-end-Medical-Chatbot-using-Llama2/.conda/lib/python3.8/site-packages (from nltk->sentence-transformers==2.2.2) (1.3.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /Users/rachana/experiments/End-to-end-Medical-Chatbot-using-Llama2/.conda/lib/python3.8/site-packages (from scikit-learn->sentence-transformers==2.2.2) (3.4.0)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /Users/rachana/experiments/End-to-end-Medical-Chatbot-using-Llama2/.conda/lib/python3.8/site-packages (from torchvision->sentence-transformers==2.2.2) (10.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/rachana/experiments/End-to-end-Medical-Chatbot-using-Llama2/.conda/lib/python3.8/site-packages (from jinja2->torch>=1.6.0->sentence-transformers==2.2.2) (2.1.5)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/rachana/experiments/End-to-end-Medical-Chatbot-using-Llama2/.conda/lib/python3.8/site-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers==2.2.2) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/rachana/experiments/End-to-end-Medical-Chatbot-using-Llama2/.conda/lib/python3.8/site-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers==2.2.2) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/rachana/experiments/End-to-end-Medical-Chatbot-using-Llama2/.conda/lib/python3.8/site-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers==2.2.2) (1.26.18)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/rachana/experiments/End-to-end-Medical-Chatbot-using-Llama2/.conda/lib/python3.8/site-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers==2.2.2) (2024.2.2)\n",
      "Requirement already satisfied: mpmath>=0.19 in /Users/rachana/experiments/End-to-end-Medical-Chatbot-using-Llama2/.conda/lib/python3.8/site-packages (from sympy->torch>=1.6.0->sentence-transformers==2.2.2) (1.3.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: flask in /Users/rachana/experiments/End-to-end-Medical-Chatbot-using-Llama2/.conda/lib/python3.8/site-packages (3.0.3)\n",
      "Requirement already satisfied: Werkzeug>=3.0.0 in /Users/rachana/experiments/End-to-end-Medical-Chatbot-using-Llama2/.conda/lib/python3.8/site-packages (from flask) (3.0.2)\n",
      "Requirement already satisfied: Jinja2>=3.1.2 in /Users/rachana/experiments/End-to-end-Medical-Chatbot-using-Llama2/.conda/lib/python3.8/site-packages (from flask) (3.1.3)\n",
      "Requirement already satisfied: itsdangerous>=2.1.2 in /Users/rachana/experiments/End-to-end-Medical-Chatbot-using-Llama2/.conda/lib/python3.8/site-packages (from flask) (2.1.2)\n",
      "Requirement already satisfied: click>=8.1.3 in /Users/rachana/experiments/End-to-end-Medical-Chatbot-using-Llama2/.conda/lib/python3.8/site-packages (from flask) (8.1.7)\n",
      "Requirement already satisfied: blinker>=1.6.2 in /Users/rachana/experiments/End-to-end-Medical-Chatbot-using-Llama2/.conda/lib/python3.8/site-packages (from flask) (1.7.0)\n",
      "Requirement already satisfied: importlib-metadata>=3.6.0 in /Users/rachana/experiments/End-to-end-Medical-Chatbot-using-Llama2/.conda/lib/python3.8/site-packages (from flask) (7.1.0)\n",
      "Requirement already satisfied: zipp>=0.5 in /Users/rachana/experiments/End-to-end-Medical-Chatbot-using-Llama2/.conda/lib/python3.8/site-packages (from importlib-metadata>=3.6.0->flask) (3.18.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/rachana/experiments/End-to-end-Medical-Chatbot-using-Llama2/.conda/lib/python3.8/site-packages (from Jinja2>=3.1.2->flask) (2.1.5)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: pypdf in /Users/rachana/experiments/End-to-end-Medical-Chatbot-using-Llama2/.conda/lib/python3.8/site-packages (4.2.0)\n",
      "Requirement already satisfied: typing_extensions>=4.0 in /Users/rachana/experiments/End-to-end-Medical-Chatbot-using-Llama2/.conda/lib/python3.8/site-packages (from pypdf) (4.11.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: python-dotenv in /Users/rachana/experiments/End-to-end-Medical-Chatbot-using-Llama2/.conda/lib/python3.8/site-packages (1.0.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Collecting langchain-pinecone\n",
      "  Using cached langchain_pinecone-0.0.3-py3-none-any.whl.metadata (1.4 kB)\n",
      "Requirement already satisfied: langchain-core<0.2,>=0.1 in /Users/rachana/experiments/End-to-end-Medical-Chatbot-using-Llama2/.conda/lib/python3.8/site-packages (from langchain-pinecone) (0.1.23)\n",
      "Requirement already satisfied: numpy<2,>=1 in /Users/rachana/experiments/End-to-end-Medical-Chatbot-using-Llama2/.conda/lib/python3.8/site-packages (from langchain-pinecone) (1.24.4)\n",
      "Requirement already satisfied: pinecone-client<4,>=3 in /Users/rachana/experiments/End-to-end-Medical-Chatbot-using-Llama2/.conda/lib/python3.8/site-packages (from langchain-pinecone) (3.1.0)\n",
      "Requirement already satisfied: PyYAML>=5.3 in /Users/rachana/experiments/End-to-end-Medical-Chatbot-using-Llama2/.conda/lib/python3.8/site-packages (from langchain-core<0.2,>=0.1->langchain-pinecone) (6.0.1)\n",
      "Requirement already satisfied: anyio<5,>=3 in /Users/rachana/experiments/End-to-end-Medical-Chatbot-using-Llama2/.conda/lib/python3.8/site-packages (from langchain-core<0.2,>=0.1->langchain-pinecone) (4.3.0)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /Users/rachana/experiments/End-to-end-Medical-Chatbot-using-Llama2/.conda/lib/python3.8/site-packages (from langchain-core<0.2,>=0.1->langchain-pinecone) (1.33)\n",
      "Requirement already satisfied: langsmith<0.0.88,>=0.0.87 in /Users/rachana/experiments/End-to-end-Medical-Chatbot-using-Llama2/.conda/lib/python3.8/site-packages (from langchain-core<0.2,>=0.1->langchain-pinecone) (0.0.87)\n",
      "Requirement already satisfied: packaging<24.0,>=23.2 in /Users/rachana/experiments/End-to-end-Medical-Chatbot-using-Llama2/.conda/lib/python3.8/site-packages (from langchain-core<0.2,>=0.1->langchain-pinecone) (23.2)\n",
      "Requirement already satisfied: pydantic<3,>=1 in /Users/rachana/experiments/End-to-end-Medical-Chatbot-using-Llama2/.conda/lib/python3.8/site-packages (from langchain-core<0.2,>=0.1->langchain-pinecone) (1.10.15)\n",
      "Requirement already satisfied: requests<3,>=2 in /Users/rachana/experiments/End-to-end-Medical-Chatbot-using-Llama2/.conda/lib/python3.8/site-packages (from langchain-core<0.2,>=0.1->langchain-pinecone) (2.31.0)\n",
      "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /Users/rachana/experiments/End-to-end-Medical-Chatbot-using-Llama2/.conda/lib/python3.8/site-packages (from langchain-core<0.2,>=0.1->langchain-pinecone) (8.2.3)\n",
      "Requirement already satisfied: certifi>=2019.11.17 in /Users/rachana/experiments/End-to-end-Medical-Chatbot-using-Llama2/.conda/lib/python3.8/site-packages (from pinecone-client<4,>=3->langchain-pinecone) (2024.2.2)\n",
      "Requirement already satisfied: tqdm>=4.64.1 in /Users/rachana/experiments/End-to-end-Medical-Chatbot-using-Llama2/.conda/lib/python3.8/site-packages (from pinecone-client<4,>=3->langchain-pinecone) (4.66.2)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4 in /Users/rachana/experiments/End-to-end-Medical-Chatbot-using-Llama2/.conda/lib/python3.8/site-packages (from pinecone-client<4,>=3->langchain-pinecone) (4.11.0)\n",
      "Requirement already satisfied: urllib3>=1.26.0 in /Users/rachana/experiments/End-to-end-Medical-Chatbot-using-Llama2/.conda/lib/python3.8/site-packages (from pinecone-client<4,>=3->langchain-pinecone) (1.26.18)\n",
      "Requirement already satisfied: idna>=2.8 in /Users/rachana/experiments/End-to-end-Medical-Chatbot-using-Llama2/.conda/lib/python3.8/site-packages (from anyio<5,>=3->langchain-core<0.2,>=0.1->langchain-pinecone) (3.6)\n",
      "Requirement already satisfied: sniffio>=1.1 in /Users/rachana/experiments/End-to-end-Medical-Chatbot-using-Llama2/.conda/lib/python3.8/site-packages (from anyio<5,>=3->langchain-core<0.2,>=0.1->langchain-pinecone) (1.3.1)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in /Users/rachana/experiments/End-to-end-Medical-Chatbot-using-Llama2/.conda/lib/python3.8/site-packages (from anyio<5,>=3->langchain-core<0.2,>=0.1->langchain-pinecone) (1.2.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /Users/rachana/experiments/End-to-end-Medical-Chatbot-using-Llama2/.conda/lib/python3.8/site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.2,>=0.1->langchain-pinecone) (2.4)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/rachana/experiments/End-to-end-Medical-Chatbot-using-Llama2/.conda/lib/python3.8/site-packages (from requests<3,>=2->langchain-core<0.2,>=0.1->langchain-pinecone) (3.3.2)\n",
      "Using cached langchain_pinecone-0.0.3-py3-none-any.whl (8.3 kB)\n",
      "Installing collected packages: langchain-pinecone\n",
      "Successfully installed langchain-pinecone-0.0.3\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install ctransformers==0.2.5\n",
    "%pip install sentence-transformers==2.2.2\n",
    "%pip install flask\n",
    "%pip install pypdf\n",
    "%pip install python-dotenv\n",
    "%pip install -U langchain-pinecone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rachana/experiments/End-to-end-Medical-Chatbot-using-Llama2/.conda/lib/python3.8/site-packages/pinecone/data/index.py:1: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from tqdm.autonotebook import tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "import pinecone\n",
    "from langchain.document_loaders import PyPDFLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "PINECONE_API_KEY = \"513a00d6-cd4a-4713-9286-bc58248b8c06\"\n",
    "PINECONE_API_ENV = \"gcp-starter\"\n",
    "host =\"https://medical-chatbot-5g67xuc.svc.gcp-starter.pinecone.io\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import PyPDFLoader, DirectoryLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.llms import CTransformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_pdf(data):\n",
    "    loader = DirectoryLoader(data,\n",
    "                    glob=\"*.pdf\",\n",
    "                    loader_cls=PyPDFLoader)\n",
    "    \n",
    "    documents = loader.load()\n",
    "\n",
    "    return documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/rachana/experiments/End-to-end-Medical-Chatbot-using-Llama2\n"
     ]
    }
   ],
   "source": [
    "%pwd\n",
    "%cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "extracted_data = load_pdf(\"data/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create text chunks\n",
    "def text_split(extracted_data):\n",
    "    text_splitter = RecursiveCharacterTextSplitter(chunk_size = 500, chunk_overlap = 20)\n",
    "    text_chunks = text_splitter.split_documents(extracted_data)\n",
    "\n",
    "    return text_chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_chunks = text_split(extracted_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import RetrievalQA\n",
    "from langchain.embeddings import HuggingFaceEmbeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_hugging_face_embeddings():\n",
    "    embeddings = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n",
    "    return embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = download_hugging_face_embeddings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pinecone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pinecone import Pinecone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "pc = Pinecone(api_key=\"513a00d6-cd4a-4713-9286-bc58248b8c06\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_name=\"medical-chatbot\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "pc_index = pc.Index(index_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.vectorstores import Pinecone as PC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs_chunks = [t.page_content for t in text_chunks]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"PINECONE_API_KEY\"] = PINECONE_API_KEY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "pinecone_index = PC.from_texts(\n",
    "    docs_chunks,\n",
    "    embeddings,\n",
    "    index_name=index_name\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langchain_community.vectorstores.pinecone.Pinecone at 0x126794e20>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pinecone_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result [Document(page_content=\"GALE ENCYCLOPEDIA OF MEDICINE 2 117Allergies\\nAllergic rhinitis is commonly triggered by\\nexposure to household dust, animal fur,or pollen. The foreign substance thattriggers an allergic reaction is calledan allergen.\\nThe presence of an allergen causes the\\nbody's lymphocytes to begin producingIgE antibodies. The lymphocytes of an allergy sufferer produce an unusuallylarge amount of IgE.\\nIgE molecules attach to mast\\ncells, which contain histamine.HistaminePollen grains\\nLymphocyte\\nFIRST EXPOSURE\"), Document(page_content='allergens are the following:\\n• plant pollens\\n• animal fur and dander\\n• body parts from house mites (microscopic creatures\\nfound in all houses)\\n• house dust• mold spores• cigarette smoke• solvents• cleaners\\nCommon food allergens include the following:\\n• nuts, especially peanuts, walnuts, and brazil nuts\\n• fish, mollusks, and shellfish• eggs• wheat• milk• food additives and preservatives\\nThe following types of drugs commonly cause aller-\\ngic reactions:\\n• penicillin or other antibiotics'), Document(page_content='itchy, scratchy nose, eyes, and throat common in aller-gic rhinitis.\\nThe number of possible airborne allergens is enor-')]\n"
     ]
    }
   ],
   "source": [
    "query = \"What are Allergies\"\n",
    "\n",
    "docs=pinecone_index.similarity_search(query, k=3)\n",
    "\n",
    "print(\"Result\", docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_template=\"\"\"\n",
    "Use the following pieces of information to answer the user's question.\n",
    "If you don't know the answer, just say that you don't know, don't try to make up an answer.\n",
    "\n",
    "Context: {context}\n",
    "Question: {question}\n",
    "\n",
    "Only return the helpful answer below and nothing else.\n",
    "Helpful answer:\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "PROMPT=PromptTemplate(template=prompt_template, input_variables=[\"context\", \"question\"])\n",
    "chain_type_kwargs={\"prompt\": PROMPT}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/rachana/experiments/End-to-end-Medical-Chatbot-using-Llama2'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "ename": "RepositoryNotFoundError",
     "evalue": "401 Client Error. (Request ID: Root=1-661377d8-324e0eb979b08a1c7209b7aa;9f1914f7-c6aa-4f5e-87e3-33673a996080)\n\nRepository Not Found for url: https://huggingface.co/api/models/model/llama-2-7b-chat.ggmlv3.q4_0.bin/revision/main.\nPlease make sure you specified the correct `repo_id` and `repo_type`.\nIf you are trying to access a private or gated repo, make sure you are authenticated.\nInvalid username or password.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mHTTPError\u001b[0m                                 Traceback (most recent call last)",
      "File \u001b[0;32m~/experiments/End-to-end-Medical-Chatbot-using-Llama2/.conda/lib/python3.8/site-packages/huggingface_hub/utils/_errors.py:304\u001b[0m, in \u001b[0;36mhf_raise_for_status\u001b[0;34m(response, endpoint_name)\u001b[0m\n\u001b[1;32m    303\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 304\u001b[0m     \u001b[43mresponse\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mraise_for_status\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    305\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m HTTPError \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[0;32m~/experiments/End-to-end-Medical-Chatbot-using-Llama2/.conda/lib/python3.8/site-packages/requests/models.py:1021\u001b[0m, in \u001b[0;36mResponse.raise_for_status\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1020\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m http_error_msg:\n\u001b[0;32m-> 1021\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m HTTPError(http_error_msg, response\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m)\n",
      "\u001b[0;31mHTTPError\u001b[0m: 401 Client Error: Unauthorized for url: https://huggingface.co/api/models/model/llama-2-7b-chat.ggmlv3.q4_0.bin/revision/main",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mRepositoryNotFoundError\u001b[0m                   Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[34], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m llm\u001b[38;5;241m=\u001b[39m\u001b[43mCTransformers\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmodel/llama-2-7b-chat.ggmlv3.q4_0.bin\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[43m                  \u001b[49m\u001b[43mmodel_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mllama\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m                  \u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmax_new_tokens\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[38;5;241;43m512\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m                          \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtemperature\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[38;5;241;43m0.8\u001b[39;49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/experiments/End-to-end-Medical-Chatbot-using-Llama2/.conda/lib/python3.8/site-packages/langchain_core/load/serializable.py:107\u001b[0m, in \u001b[0;36mSerializable.__init__\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m    106\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 107\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    108\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lc_kwargs \u001b[38;5;241m=\u001b[39m kwargs\n",
      "File \u001b[0;32m~/experiments/End-to-end-Medical-Chatbot-using-Llama2/.conda/lib/python3.8/site-packages/pydantic/main.py:339\u001b[0m, in \u001b[0;36mpydantic.main.BaseModel.__init__\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/experiments/End-to-end-Medical-Chatbot-using-Llama2/.conda/lib/python3.8/site-packages/pydantic/main.py:1100\u001b[0m, in \u001b[0;36mpydantic.main.validate_model\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/experiments/End-to-end-Medical-Chatbot-using-Llama2/.conda/lib/python3.8/site-packages/langchain_community/llms/ctransformers.py:72\u001b[0m, in \u001b[0;36mCTransformers.validate_environment\u001b[0;34m(cls, values)\u001b[0m\n\u001b[1;32m     66\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(\n\u001b[1;32m     67\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCould not import `ctransformers` package. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     68\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPlease install it with `pip install ctransformers`\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     69\u001b[0m     )\n\u001b[1;32m     71\u001b[0m config \u001b[38;5;241m=\u001b[39m values[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mconfig\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;129;01mor\u001b[39;00m {}\n\u001b[0;32m---> 72\u001b[0m values[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mclient\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mAutoModelForCausalLM\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     73\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmodel\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     74\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalues\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmodel_type\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     75\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel_file\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalues\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmodel_file\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     76\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlib\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalues\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlib\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     77\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     78\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     79\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m values\n",
      "File \u001b[0;32m~/experiments/End-to-end-Medical-Chatbot-using-Llama2/.conda/lib/python3.8/site-packages/ctransformers/hub.py:130\u001b[0m, in \u001b[0;36mAutoModelForCausalLM.from_pretrained\u001b[0;34m(cls, model_path_or_repo_id, model_type, model_file, config, lib, local_files_only, **kwargs)\u001b[0m\n\u001b[1;32m    103\u001b[0m \u001b[38;5;129m@classmethod\u001b[39m\n\u001b[1;32m    104\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfrom_pretrained\u001b[39m(\n\u001b[1;32m    105\u001b[0m     \u001b[38;5;28mcls\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    113\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m    114\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m LLM:\n\u001b[1;32m    115\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Loads the language model from a local file or remote repo.\u001b[39;00m\n\u001b[1;32m    116\u001b[0m \n\u001b[1;32m    117\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    128\u001b[0m \u001b[38;5;124;03m        `LLM` object.\u001b[39;00m\n\u001b[1;32m    129\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 130\u001b[0m     config \u001b[38;5;241m=\u001b[39m config \u001b[38;5;129;01mor\u001b[39;00m \u001b[43mAutoConfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    131\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodel_path_or_repo_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    132\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlocal_files_only\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlocal_files_only\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    133\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    134\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    135\u001b[0m     model_type \u001b[38;5;241m=\u001b[39m model_type \u001b[38;5;129;01mor\u001b[39;00m config\u001b[38;5;241m.\u001b[39mmodel_type\n\u001b[1;32m    136\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m model_type:\n",
      "File \u001b[0;32m~/experiments/End-to-end-Medical-Chatbot-using-Llama2/.conda/lib/python3.8/site-packages/ctransformers/hub.py:47\u001b[0m, in \u001b[0;36mAutoConfig.from_pretrained\u001b[0;34m(cls, model_path_or_repo_id, local_files_only, **kwargs)\u001b[0m\n\u001b[1;32m     45\u001b[0m     \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_update_from_dir(model_path_or_repo_id, auto_config)\n\u001b[1;32m     46\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m path_type \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrepo\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m---> 47\u001b[0m     \u001b[38;5;28;43mcls\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_update_from_repo\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     48\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodel_path_or_repo_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     49\u001b[0m \u001b[43m        \u001b[49m\u001b[43mauto_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     50\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlocal_files_only\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlocal_files_only\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     51\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     53\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m kwargs\u001b[38;5;241m.\u001b[39mitems():\n\u001b[1;32m     54\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(config, k):\n",
      "File \u001b[0;32m~/experiments/End-to-end-Medical-Chatbot-using-Llama2/.conda/lib/python3.8/site-packages/ctransformers/hub.py:69\u001b[0m, in \u001b[0;36mAutoConfig._update_from_repo\u001b[0;34m(cls, repo_id, auto_config, local_files_only)\u001b[0m\n\u001b[1;32m     62\u001b[0m \u001b[38;5;129m@classmethod\u001b[39m\n\u001b[1;32m     63\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_update_from_repo\u001b[39m(\n\u001b[1;32m     64\u001b[0m     \u001b[38;5;28mcls\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     67\u001b[0m     local_files_only: \u001b[38;5;28mbool\u001b[39m,\n\u001b[1;32m     68\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m---> 69\u001b[0m     path \u001b[38;5;241m=\u001b[39m \u001b[43msnapshot_download\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     70\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrepo_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrepo_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     71\u001b[0m \u001b[43m        \u001b[49m\u001b[43mallow_patterns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mconfig.json\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     72\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlocal_files_only\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlocal_files_only\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     73\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     74\u001b[0m     \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_update_from_dir(path, auto_config)\n",
      "File \u001b[0;32m~/experiments/End-to-end-Medical-Chatbot-using-Llama2/.conda/lib/python3.8/site-packages/huggingface_hub/utils/_validators.py:119\u001b[0m, in \u001b[0;36mvalidate_hf_hub_args.<locals>._inner_fn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    116\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m check_use_auth_token:\n\u001b[1;32m    117\u001b[0m     kwargs \u001b[38;5;241m=\u001b[39m smoothly_deprecate_use_auth_token(fn_name\u001b[38;5;241m=\u001b[39mfn\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, has_token\u001b[38;5;241m=\u001b[39mhas_token, kwargs\u001b[38;5;241m=\u001b[39mkwargs)\n\u001b[0;32m--> 119\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/experiments/End-to-end-Medical-Chatbot-using-Llama2/.conda/lib/python3.8/site-packages/huggingface_hub/_snapshot_download.py:255\u001b[0m, in \u001b[0;36msnapshot_download\u001b[0;34m(repo_id, repo_type, revision, cache_dir, local_dir, local_dir_use_symlinks, library_name, library_version, user_agent, proxies, etag_timeout, resume_download, force_download, token, local_files_only, allow_patterns, ignore_patterns, max_workers, tqdm_class, headers, endpoint)\u001b[0m\n\u001b[1;32m    248\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m LocalEntryNotFoundError(\n\u001b[1;32m    249\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot find an appropriate cached snapshot folder for the specified revision on the local disk and \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    250\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moutgoing traffic has been disabled. To enable repo look-ups and downloads online, set \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    251\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mHF_HUB_OFFLINE=0\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m as environment variable.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    252\u001b[0m     ) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mapi_call_error\u001b[39;00m\n\u001b[1;32m    253\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(api_call_error, RepositoryNotFoundError) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(api_call_error, GatedRepoError):\n\u001b[1;32m    254\u001b[0m     \u001b[38;5;66;03m# Repo not found => let's raise the actual error\u001b[39;00m\n\u001b[0;32m--> 255\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m api_call_error\n\u001b[1;32m    256\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    257\u001b[0m     \u001b[38;5;66;03m# Otherwise: most likely a connection issue or Hub downtime => let's warn the user\u001b[39;00m\n\u001b[1;32m    258\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m LocalEntryNotFoundError(\n\u001b[1;32m    259\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAn error happened while trying to locate the files on the Hub and we cannot find the appropriate\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    260\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m snapshot folder for the specified revision on the local disk. Please check your internet connection\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    261\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m and try again.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    262\u001b[0m     ) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mapi_call_error\u001b[39;00m\n",
      "File \u001b[0;32m~/experiments/End-to-end-Medical-Chatbot-using-Llama2/.conda/lib/python3.8/site-packages/huggingface_hub/_snapshot_download.py:186\u001b[0m, in \u001b[0;36msnapshot_download\u001b[0;34m(repo_id, repo_type, revision, cache_dir, local_dir, local_dir_use_symlinks, library_name, library_version, user_agent, proxies, etag_timeout, resume_download, force_download, token, local_files_only, allow_patterns, ignore_patterns, max_workers, tqdm_class, headers, endpoint)\u001b[0m\n\u001b[1;32m    177\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    178\u001b[0m     \u001b[38;5;66;03m# if we have internet connection we want to list files to download\u001b[39;00m\n\u001b[1;32m    179\u001b[0m     api \u001b[38;5;241m=\u001b[39m HfApi(\n\u001b[1;32m    180\u001b[0m         library_name\u001b[38;5;241m=\u001b[39mlibrary_name,\n\u001b[1;32m    181\u001b[0m         library_version\u001b[38;5;241m=\u001b[39mlibrary_version,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    184\u001b[0m         headers\u001b[38;5;241m=\u001b[39mheaders,\n\u001b[1;32m    185\u001b[0m     )\n\u001b[0;32m--> 186\u001b[0m     repo_info \u001b[38;5;241m=\u001b[39m \u001b[43mapi\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrepo_info\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrepo_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrepo_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrepo_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrepo_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrevision\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrevision\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtoken\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtoken\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    187\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (requests\u001b[38;5;241m.\u001b[39mexceptions\u001b[38;5;241m.\u001b[39mSSLError, requests\u001b[38;5;241m.\u001b[39mexceptions\u001b[38;5;241m.\u001b[39mProxyError):\n\u001b[1;32m    188\u001b[0m     \u001b[38;5;66;03m# Actually raise for those subclasses of ConnectionError\u001b[39;00m\n\u001b[1;32m    189\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m\n",
      "File \u001b[0;32m~/experiments/End-to-end-Medical-Chatbot-using-Llama2/.conda/lib/python3.8/site-packages/huggingface_hub/utils/_validators.py:119\u001b[0m, in \u001b[0;36mvalidate_hf_hub_args.<locals>._inner_fn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    116\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m check_use_auth_token:\n\u001b[1;32m    117\u001b[0m     kwargs \u001b[38;5;241m=\u001b[39m smoothly_deprecate_use_auth_token(fn_name\u001b[38;5;241m=\u001b[39mfn\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, has_token\u001b[38;5;241m=\u001b[39mhas_token, kwargs\u001b[38;5;241m=\u001b[39mkwargs)\n\u001b[0;32m--> 119\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/experiments/End-to-end-Medical-Chatbot-using-Llama2/.conda/lib/python3.8/site-packages/huggingface_hub/hf_api.py:2418\u001b[0m, in \u001b[0;36mHfApi.repo_info\u001b[0;34m(self, repo_id, revision, repo_type, timeout, files_metadata, token)\u001b[0m\n\u001b[1;32m   2416\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   2417\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnsupported repo type.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m-> 2418\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmethod\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2419\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrepo_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2420\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrevision\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrevision\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2421\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtoken\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtoken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2422\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2423\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfiles_metadata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfiles_metadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2424\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/experiments/End-to-end-Medical-Chatbot-using-Llama2/.conda/lib/python3.8/site-packages/huggingface_hub/utils/_validators.py:119\u001b[0m, in \u001b[0;36mvalidate_hf_hub_args.<locals>._inner_fn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    116\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m check_use_auth_token:\n\u001b[1;32m    117\u001b[0m     kwargs \u001b[38;5;241m=\u001b[39m smoothly_deprecate_use_auth_token(fn_name\u001b[38;5;241m=\u001b[39mfn\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, has_token\u001b[38;5;241m=\u001b[39mhas_token, kwargs\u001b[38;5;241m=\u001b[39mkwargs)\n\u001b[0;32m--> 119\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/experiments/End-to-end-Medical-Chatbot-using-Llama2/.conda/lib/python3.8/site-packages/huggingface_hub/hf_api.py:2228\u001b[0m, in \u001b[0;36mHfApi.model_info\u001b[0;34m(self, repo_id, revision, timeout, securityStatus, files_metadata, token)\u001b[0m\n\u001b[1;32m   2226\u001b[0m     params[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mblobs\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m   2227\u001b[0m r \u001b[38;5;241m=\u001b[39m get_session()\u001b[38;5;241m.\u001b[39mget(path, headers\u001b[38;5;241m=\u001b[39mheaders, timeout\u001b[38;5;241m=\u001b[39mtimeout, params\u001b[38;5;241m=\u001b[39mparams)\n\u001b[0;32m-> 2228\u001b[0m \u001b[43mhf_raise_for_status\u001b[49m\u001b[43m(\u001b[49m\u001b[43mr\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2229\u001b[0m data \u001b[38;5;241m=\u001b[39m r\u001b[38;5;241m.\u001b[39mjson()\n\u001b[1;32m   2230\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m ModelInfo(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mdata)\n",
      "File \u001b[0;32m~/experiments/End-to-end-Medical-Chatbot-using-Llama2/.conda/lib/python3.8/site-packages/huggingface_hub/utils/_errors.py:352\u001b[0m, in \u001b[0;36mhf_raise_for_status\u001b[0;34m(response, endpoint_name)\u001b[0m\n\u001b[1;32m    333\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m error_code \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRepoNotFound\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[1;32m    334\u001b[0m     response\u001b[38;5;241m.\u001b[39mstatus_code \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m401\u001b[39m\n\u001b[1;32m    335\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m response\u001b[38;5;241m.\u001b[39mrequest \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    342\u001b[0m     \u001b[38;5;66;03m# => for now, we process them as `RepoNotFound` anyway.\u001b[39;00m\n\u001b[1;32m    343\u001b[0m     \u001b[38;5;66;03m# See https://gist.github.com/Wauplin/46c27ad266b15998ce56a6603796f0b9\u001b[39;00m\n\u001b[1;32m    344\u001b[0m     message \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    345\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresponse\u001b[38;5;241m.\u001b[39mstatus_code\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m Client Error.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    346\u001b[0m         \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    350\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m make sure you are authenticated.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    351\u001b[0m     )\n\u001b[0;32m--> 352\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m RepositoryNotFoundError(message, response) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n\u001b[1;32m    354\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m response\u001b[38;5;241m.\u001b[39mstatus_code \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m400\u001b[39m:\n\u001b[1;32m    355\u001b[0m     message \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    356\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mBad request for \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mendpoint_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m endpoint:\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m endpoint_name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mBad request:\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    357\u001b[0m     )\n",
      "\u001b[0;31mRepositoryNotFoundError\u001b[0m: 401 Client Error. (Request ID: Root=1-661377d8-324e0eb979b08a1c7209b7aa;9f1914f7-c6aa-4f5e-87e3-33673a996080)\n\nRepository Not Found for url: https://huggingface.co/api/models/model/llama-2-7b-chat.ggmlv3.q4_0.bin/revision/main.\nPlease make sure you specified the correct `repo_id` and `repo_type`.\nIf you are trying to access a private or gated repo, make sure you are authenticated.\nInvalid username or password."
     ]
    }
   ],
   "source": [
    "llm=CTransformers(model=\"model/llama-2-7b-chat.ggmlv3.q4_0.bin\",\n",
    "                  model_type=\"llama\",\n",
    "                  config={'max_new_tokens':512,\n",
    "                          'temperature':0.8})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
